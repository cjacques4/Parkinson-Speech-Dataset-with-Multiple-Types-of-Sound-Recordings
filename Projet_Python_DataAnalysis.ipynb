{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push sur Git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master c3ab10e] Prétraitement + Test SVM\n",
      " 1 file changed, 55 insertions(+), 91 deletions(-)\n",
      "Counting objects: 3, done.\n",
      "Delta compression using up to 4 threads.\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 833 bytes | 833.00 KiB/s, done.\n",
      "Total 3 (delta 1), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
      "To https://github.com/cjacques4/Parkinson-Speech-Dataset-with-Multiple-Types-of-Sound-Recordings.git\n",
      "   c225956..c3ab10e  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git add Projet_Python_DataAnalysis.ipynb\n",
    "!git commit -m \"Prétraitement + Test SVM\"\n",
    "!git push "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Téléchargement de la base de données via WebScrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"./chromedriver\")\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/datasets/Parkinson+Speech+Dataset+with++Multiple+Types+of+Sound+Recordings#\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger le dataset\n",
    "driver.find_element_by_link_text('Data Folder').click()\n",
    "xpath = '/html/body/table/tbody/tr[4]/td[2]/a'\n",
    "driver.find_element_by_xpath(xpath).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importer la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajout header car il n'y avait pas le nom des colonnes\n",
    " \n",
    "df = pd.read_csv ('train_data.txt', delimiter=\",\", header=0, index_col = [0], \n",
    "                        names=['id',\n",
    "                               'Jitter_local','Jitter_local_absolute','Jitter_rap','Jitter_ppq5','Jitter_ddp',\n",
    "                               'Shimmer_local','Shimmer_local_dB','Shimmer_apq3','Shimmer_apq5', 'Shimmer_apq11','Shimmer_dda', \n",
    "                               'AC','NTH','HTN', \n",
    "                               'Median_pitch','Mean_pitch','Standard_deviation','Minimum_pitch','Maximum_pitch',\n",
    "                               'Number_of_pulses','Number_of_periods','Mean_period','Standard_deviation_of_period',\n",
    "                               'Fraction_of_locally_unvoiced_frames','Number_of_voice_breaks','Degree_of_voice_breaks',\n",
    "                               'UPDRS', \n",
    "                               'class_information']) \n",
    "  \n",
    "#df_train.head()\n",
    "\n",
    "df_val = pd.read_csv ('test_data.txt', delimiter=\",\", header=0, index_col = [0], \n",
    "                        names=['id',\n",
    "                               'Jitter_local','Jitter_local_absolute','Jitter_rap','Jitter_ppq5','Jitter_ddp',\n",
    "                               'Shimmer_local','Shimmer_local_dB','Shimmer_apq3','Shimmer_apq5', 'Shimmer_apq11','Shimmer_dda', \n",
    "                               'AC','NTH','HTN', \n",
    "                               'Median_pitch','Mean_pitch','Standard_deviation','Minimum_pitch','Maximum_pitch',\n",
    "                               'Number_of_pulses','Number_of_periods','Mean_period','Standard_deviation_of_period',\n",
    "                               'Fraction_of_locally_unvoiced_frames','Number_of_voice_breaks','Degree_of_voice_breaks', \n",
    "                               'class_information']) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jitter_local                           float64\n",
       "Jitter_local_absolute                  float64\n",
       "Jitter_rap                             float64\n",
       "Jitter_ppq5                            float64\n",
       "Jitter_ddp                             float64\n",
       "Shimmer_local                          float64\n",
       "Shimmer_local_dB                       float64\n",
       "Shimmer_apq3                           float64\n",
       "Shimmer_apq5                           float64\n",
       "Shimmer_apq11                          float64\n",
       "Shimmer_dda                            float64\n",
       "AC                                     float64\n",
       "NTH                                    float64\n",
       "HTN                                    float64\n",
       "Median_pitch                           float64\n",
       "Mean_pitch                             float64\n",
       "Standard_deviation                     float64\n",
       "Minimum_pitch                          float64\n",
       "Maximum_pitch                          float64\n",
       "Number_of_pulses                         int64\n",
       "Number_of_periods                        int64\n",
       "Mean_period                            float64\n",
       "Standard_deviation_of_period           float64\n",
       "Fraction_of_locally_unvoiced_frames    float64\n",
       "Number_of_voice_breaks                   int64\n",
       "Degree_of_voice_breaks                 float64\n",
       "UPDRS                                    int64\n",
       "class_information                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      "Jitter_local                           0\n",
      "Jitter_local_absolute                  0\n",
      "Jitter_rap                             0\n",
      "Jitter_ppq5                            0\n",
      "Jitter_ddp                             0\n",
      "Shimmer_local                          0\n",
      "Shimmer_local_dB                       0\n",
      "Shimmer_apq3                           0\n",
      "Shimmer_apq5                           0\n",
      "Shimmer_apq11                          0\n",
      "Shimmer_dda                            0\n",
      "AC                                     0\n",
      "NTH                                    0\n",
      "HTN                                    0\n",
      "Median_pitch                           0\n",
      "Mean_pitch                             0\n",
      "Standard_deviation                     0\n",
      "Minimum_pitch                          0\n",
      "Maximum_pitch                          0\n",
      "Number_of_pulses                       0\n",
      "Number_of_periods                      0\n",
      "Mean_period                            0\n",
      "Standard_deviation_of_period           0\n",
      "Fraction_of_locally_unvoiced_frames    0\n",
      "Number_of_voice_breaks                 0\n",
      "Degree_of_voice_breaks                 0\n",
      "UPDRS                                  0\n",
      "class_information                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check NA \n",
    "null_counts = df.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n{}\".format(null_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data \n",
    "target = df.class_information\n",
    "df.drop(['class_information'], axis='columns', inplace=True)\n",
    "x = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)                 \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGO SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "algorithme = svm.SVC()\n",
    "algorithme.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50432277, 0.49710983, 0.50289017])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "cross_validation.cross_val_score(algorithme, x, target, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8879310344827587 0.9037900874635568\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params={}, iid=True, n_jobs=-1,\n",
      "       param_grid={'gamma': [0.1, 0.01, 0.001, 0.0001], 'probability': [True]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "#Aller au delà des params par défauts \n",
    "\n",
    "from sklearn import grid_search\n",
    "parameters = {  'gamma' : [0.1,0.01, 0.001, 0.0001]           ,\n",
    "                 \"probability\" : [True]}\n",
    "grid       = grid_search.GridSearchCV(algorithme, parameters, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print (grid.best_score_, grid.best_estimator_.score(X_test, y_test))\n",
    "\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885057471264368 SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "parameters = {  'C'      : [1,10, 100]             ,\n",
    "                'gamma' : [0.1,0.01, 0.001, 0.0001]\n",
    "                      }\n",
    "grid = grid_search.GridSearchCV(svm.SVC(), parameters, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print (grid.best_score_, grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885057471264368 SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "parameters = {  'C'      : [1,10, 100]             ,\n",
    "                'gamma' : [0.1,0.01, 0.001, 0.0001],\n",
    "                'kernel' : ['rbf', 'poly', 'sigmoid']\n",
    "                 }\n",
    "grid = grid_search.GridSearchCV(svm.SVC(), parameters, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print (grid.best_score_, grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester tous les algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sklearn_algorithms(verbose = False):\n",
    "    \"\"\"\n",
    "    Explore all submodule of sklearn and fetch functions having a 'fit' attribute.\n",
    "    \n",
    "    Be careful : some functions are not models (ex : crossvalidators)\n",
    "    Parameters :\n",
    "        debug = print or not stuff on console\n",
    "    Return :\n",
    "        dict : { module : [ fit_functions] }\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    import importlib\n",
    "    import sklearn\n",
    "    algos = defaultdict(list)\n",
    "    if verbose : print (dir(sklearn))\n",
    "    for nom_module in sklearn.__dict__['__all__']:    \n",
    "        if verbose : print (nom_module)\n",
    "        try:\n",
    "            to_import = \"sklearn.%s\"%nom_module\n",
    "            module    = importlib.import_module(to_import)\n",
    "            for nom_fonction in dir(module):\n",
    "                fonction = getattr(module, nom_fonction)\n",
    "                if hasattr(fonction, \"fit\"):\n",
    "                    if verbose : print (\" nom algorithme  = \", nom_fonction)\n",
    "                    algos[nom_module].append(fonction)                                            \n",
    "        except Exception as e:\n",
    "            if verbose : print (e)\n",
    "        if verbose: print (\"=\"*30)\n",
    "    return algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_ASSUME_FINITE', '__SKLEARN_SETUP__', '__all__', '__builtins__', '__cached__', '__check_build', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_contextmanager', 'base', 'clone', 'config_context', 'exceptions', 'externals', 'feature_selection', 'get_config', 'linear_model', 'logger', 'logging', 'metrics', 'model_selection', 'neighbors', 'os', 'preprocessing', 'random_projection', 're', 'set_config', 'setup_module', 'svm', 'sys', 'utils', 'warnings']\n",
      "calibration\n",
      " nom algorithme  =  CalibratedClassifierCV\n",
      " nom algorithme  =  IsotonicRegression\n",
      " nom algorithme  =  LabelBinarizer\n",
      " nom algorithme  =  LabelEncoder\n",
      " nom algorithme  =  LinearSVC\n",
      " nom algorithme  =  _CalibratedClassifier\n",
      " nom algorithme  =  _SigmoidCalibration\n",
      "==============================\n",
      "cluster\n",
      " nom algorithme  =  AffinityPropagation\n",
      " nom algorithme  =  AgglomerativeClustering\n",
      " nom algorithme  =  Birch\n",
      " nom algorithme  =  DBSCAN\n",
      " nom algorithme  =  FeatureAgglomeration\n",
      " nom algorithme  =  KMeans\n",
      " nom algorithme  =  MeanShift\n",
      " nom algorithme  =  MiniBatchKMeans\n",
      " nom algorithme  =  SpectralBiclustering\n",
      " nom algorithme  =  SpectralClustering\n",
      " nom algorithme  =  SpectralCoclustering\n",
      "==============================\n",
      "covariance\n",
      " nom algorithme  =  EllipticEnvelope\n",
      " nom algorithme  =  EmpiricalCovariance\n",
      " nom algorithme  =  GraphLasso\n",
      " nom algorithme  =  GraphLassoCV\n",
      " nom algorithme  =  LedoitWolf\n",
      " nom algorithme  =  MinCovDet\n",
      " nom algorithme  =  OAS\n",
      " nom algorithme  =  ShrunkCovariance\n",
      "==============================\n",
      "cross_decomposition\n",
      " nom algorithme  =  CCA\n",
      " nom algorithme  =  PLSCanonical\n",
      " nom algorithme  =  PLSRegression\n",
      " nom algorithme  =  PLSSVD\n",
      "==============================\n",
      "cross_validation\n",
      "==============================\n",
      "datasets\n",
      "==============================\n",
      "decomposition\n",
      " nom algorithme  =  DictionaryLearning\n",
      " nom algorithme  =  FactorAnalysis\n",
      " nom algorithme  =  FastICA\n",
      " nom algorithme  =  IncrementalPCA\n",
      " nom algorithme  =  KernelPCA\n",
      " nom algorithme  =  LatentDirichletAllocation\n",
      " nom algorithme  =  MiniBatchDictionaryLearning\n",
      " nom algorithme  =  MiniBatchSparsePCA\n",
      " nom algorithme  =  NMF\n",
      " nom algorithme  =  PCA\n",
      " nom algorithme  =  RandomizedPCA\n",
      " nom algorithme  =  SparseCoder\n",
      " nom algorithme  =  SparsePCA\n",
      " nom algorithme  =  TruncatedSVD\n",
      "==============================\n",
      "dummy\n",
      " nom algorithme  =  DummyClassifier\n",
      " nom algorithme  =  DummyRegressor\n",
      "==============================\n",
      "ensemble\n",
      " nom algorithme  =  AdaBoostClassifier\n",
      " nom algorithme  =  AdaBoostRegressor\n",
      " nom algorithme  =  BaggingClassifier\n",
      " nom algorithme  =  BaggingRegressor\n",
      " nom algorithme  =  ExtraTreesClassifier\n",
      " nom algorithme  =  ExtraTreesRegressor\n",
      " nom algorithme  =  GradientBoostingClassifier\n",
      " nom algorithme  =  GradientBoostingRegressor\n",
      " nom algorithme  =  IsolationForest\n",
      " nom algorithme  =  RandomForestClassifier\n",
      " nom algorithme  =  RandomForestRegressor\n",
      " nom algorithme  =  RandomTreesEmbedding\n",
      " nom algorithme  =  VotingClassifier\n",
      "==============================\n",
      "exceptions\n",
      "==============================\n",
      "externals\n",
      "==============================\n",
      "feature_extraction\n",
      " nom algorithme  =  DictVectorizer\n",
      " nom algorithme  =  FeatureHasher\n",
      "==============================\n",
      "feature_selection\n",
      " nom algorithme  =  GenericUnivariateSelect\n",
      " nom algorithme  =  RFE\n",
      " nom algorithme  =  RFECV\n",
      " nom algorithme  =  SelectFdr\n",
      " nom algorithme  =  SelectFpr\n",
      " nom algorithme  =  SelectFromModel\n",
      " nom algorithme  =  SelectFwe\n",
      " nom algorithme  =  SelectKBest\n",
      " nom algorithme  =  SelectPercentile\n",
      " nom algorithme  =  VarianceThreshold\n",
      "==============================\n",
      "gaussian_process\n",
      " nom algorithme  =  GaussianProcess\n",
      " nom algorithme  =  GaussianProcessClassifier\n",
      " nom algorithme  =  GaussianProcessRegressor\n",
      "==============================\n",
      "grid_search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nom algorithme  =  GridSearchCV\n",
      " nom algorithme  =  RandomizedSearchCV\n",
      "==============================\n",
      "isotonic\n",
      " nom algorithme  =  IsotonicRegression\n",
      "==============================\n",
      "kernel_approximation\n",
      " nom algorithme  =  AdditiveChi2Sampler\n",
      " nom algorithme  =  Nystroem\n",
      " nom algorithme  =  RBFSampler\n",
      " nom algorithme  =  SkewedChi2Sampler\n",
      "==============================\n",
      "kernel_ridge\n",
      " nom algorithme  =  KernelRidge\n",
      "==============================\n",
      "learning_curve\n",
      "==============================\n",
      "linear_model\n",
      " nom algorithme  =  ARDRegression\n",
      " nom algorithme  =  BayesianRidge\n",
      " nom algorithme  =  ElasticNet\n",
      " nom algorithme  =  ElasticNetCV\n",
      " nom algorithme  =  HuberRegressor\n",
      " nom algorithme  =  Lars\n",
      " nom algorithme  =  LarsCV\n",
      " nom algorithme  =  Lasso\n",
      " nom algorithme  =  LassoCV\n",
      " nom algorithme  =  LassoLars\n",
      " nom algorithme  =  LassoLarsCV\n",
      " nom algorithme  =  LassoLarsIC\n",
      " nom algorithme  =  LinearRegression\n",
      " nom algorithme  =  LogisticRegression\n",
      " nom algorithme  =  LogisticRegressionCV\n",
      " nom algorithme  =  MultiTaskElasticNet\n",
      " nom algorithme  =  MultiTaskElasticNetCV\n",
      " nom algorithme  =  MultiTaskLasso\n",
      " nom algorithme  =  MultiTaskLassoCV\n",
      " nom algorithme  =  OrthogonalMatchingPursuit\n",
      " nom algorithme  =  OrthogonalMatchingPursuitCV\n",
      " nom algorithme  =  PassiveAggressiveClassifier\n",
      " nom algorithme  =  PassiveAggressiveRegressor\n",
      " nom algorithme  =  Perceptron\n",
      " nom algorithme  =  RANSACRegressor\n",
      " nom algorithme  =  RandomizedLasso\n",
      " nom algorithme  =  RandomizedLogisticRegression\n",
      " nom algorithme  =  Ridge\n",
      " nom algorithme  =  RidgeCV\n",
      " nom algorithme  =  RidgeClassifier\n",
      " nom algorithme  =  RidgeClassifierCV\n",
      " nom algorithme  =  SGDClassifier\n",
      " nom algorithme  =  SGDRegressor\n",
      " nom algorithme  =  TheilSenRegressor\n",
      "==============================\n",
      "manifold\n",
      " nom algorithme  =  Isomap\n",
      " nom algorithme  =  LocallyLinearEmbedding\n",
      " nom algorithme  =  MDS\n",
      " nom algorithme  =  SpectralEmbedding\n",
      " nom algorithme  =  TSNE\n",
      "==============================\n",
      "metrics\n",
      "==============================\n",
      "mixture\n",
      " nom algorithme  =  BayesianGaussianMixture\n",
      " nom algorithme  =  DPGMM\n",
      " nom algorithme  =  GMM\n",
      " nom algorithme  =  GaussianMixture\n",
      " nom algorithme  =  VBGMM\n",
      "==============================\n",
      "model_selection\n",
      " nom algorithme  =  GridSearchCV\n",
      " nom algorithme  =  RandomizedSearchCV\n",
      "==============================\n",
      "multiclass\n",
      " nom algorithme  =  LabelBinarizer\n",
      " nom algorithme  =  OneVsOneClassifier\n",
      " nom algorithme  =  OneVsRestClassifier\n",
      " nom algorithme  =  OutputCodeClassifier\n",
      " nom algorithme  =  _ConstantPredictor\n",
      "==============================\n",
      "multioutput\n",
      " nom algorithme  =  ClassifierChain\n",
      " nom algorithme  =  MultiOutputClassifier\n",
      " nom algorithme  =  MultiOutputEstimator\n",
      " nom algorithme  =  MultiOutputRegressor\n",
      "==============================\n",
      "naive_bayes\n",
      " nom algorithme  =  BaseDiscreteNB\n",
      " nom algorithme  =  BernoulliNB\n",
      " nom algorithme  =  GaussianNB\n",
      " nom algorithme  =  LabelBinarizer\n",
      " nom algorithme  =  MultinomialNB\n",
      "==============================\n",
      "neighbors\n",
      " nom algorithme  =  KNeighborsClassifier\n",
      " nom algorithme  =  KNeighborsRegressor\n",
      " nom algorithme  =  KernelDensity\n",
      " nom algorithme  =  LSHForest\n",
      " nom algorithme  =  LocalOutlierFactor\n",
      " nom algorithme  =  NearestCentroid\n",
      " nom algorithme  =  NearestNeighbors\n",
      " nom algorithme  =  RadiusNeighborsClassifier\n",
      " nom algorithme  =  RadiusNeighborsRegressor\n",
      "==============================\n",
      "neural_network\n",
      " nom algorithme  =  BernoulliRBM\n",
      " nom algorithme  =  MLPClassifier\n",
      " nom algorithme  =  MLPRegressor\n",
      "==============================\n",
      "pipeline\n",
      " nom algorithme  =  FeatureUnion\n",
      " nom algorithme  =  Pipeline\n",
      "==============================\n",
      "preprocessing\n",
      " nom algorithme  =  Binarizer\n",
      " nom algorithme  =  FunctionTransformer\n",
      " nom algorithme  =  Imputer\n",
      " nom algorithme  =  KernelCenterer\n",
      " nom algorithme  =  LabelBinarizer\n",
      " nom algorithme  =  LabelEncoder\n",
      " nom algorithme  =  MaxAbsScaler\n",
      " nom algorithme  =  MinMaxScaler\n",
      " nom algorithme  =  MultiLabelBinarizer\n",
      " nom algorithme  =  Normalizer\n",
      " nom algorithme  =  OneHotEncoder\n",
      " nom algorithme  =  PolynomialFeatures\n",
      " nom algorithme  =  QuantileTransformer\n",
      " nom algorithme  =  RobustScaler\n",
      " nom algorithme  =  StandardScaler\n",
      "==============================\n",
      "random_projection\n",
      " nom algorithme  =  BaseRandomProjection\n",
      " nom algorithme  =  GaussianRandomProjection\n",
      " nom algorithme  =  SparseRandomProjection\n",
      "==============================\n",
      "semi_supervised\n",
      " nom algorithme  =  LabelPropagation\n",
      " nom algorithme  =  LabelSpreading\n",
      "==============================\n",
      "svm\n",
      " nom algorithme  =  LinearSVC\n",
      " nom algorithme  =  LinearSVR\n",
      " nom algorithme  =  NuSVC\n",
      " nom algorithme  =  NuSVR\n",
      " nom algorithme  =  OneClassSVM\n",
      " nom algorithme  =  SVC\n",
      " nom algorithme  =  SVR\n",
      " nom algorithme  =  libsvm\n",
      "==============================\n",
      "tree\n",
      " nom algorithme  =  DecisionTreeClassifier\n",
      " nom algorithme  =  DecisionTreeRegressor\n",
      " nom algorithme  =  ExtraTreeClassifier\n",
      " nom algorithme  =  ExtraTreeRegressor\n",
      "==============================\n",
      "discriminant_analysis\n",
      " nom algorithme  =  LinearDiscriminantAnalysis\n",
      " nom algorithme  =  QuadraticDiscriminantAnalysis\n",
      " nom algorithme  =  StandardScaler\n",
      "==============================\n",
      "clone\n",
      "No module named 'sklearn.clone'\n",
      "==============================\n",
      "\n",
      "===> calibration\n",
      "CalibratedClassifierCV,IsotonicRegression,LabelBinarizer,LabelEncoder,LinearSVC,_CalibratedClassifier,_SigmoidCalibration\n",
      "\n",
      "===> cluster\n",
      "AffinityPropagation,AgglomerativeClustering,Birch,DBSCAN,FeatureAgglomeration,KMeans,MeanShift,MiniBatchKMeans,SpectralBiclustering,SpectralClustering,SpectralCoclustering\n",
      "\n",
      "===> covariance\n",
      "EllipticEnvelope,EmpiricalCovariance,GraphLasso,GraphLassoCV,LedoitWolf,MinCovDet,OAS,ShrunkCovariance\n",
      "\n",
      "===> cross_decomposition\n",
      "CCA,PLSCanonical,PLSRegression,PLSSVD\n",
      "\n",
      "===> decomposition\n",
      "DictionaryLearning,FactorAnalysis,FastICA,IncrementalPCA,KernelPCA,LatentDirichletAllocation,MiniBatchDictionaryLearning,MiniBatchSparsePCA,NMF,PCA,RandomizedPCA,SparseCoder,SparsePCA,TruncatedSVD\n",
      "\n",
      "===> dummy\n",
      "DummyClassifier,DummyRegressor\n",
      "\n",
      "===> ensemble\n",
      "AdaBoostClassifier,AdaBoostRegressor,BaggingClassifier,BaggingRegressor,ExtraTreesClassifier,ExtraTreesRegressor,GradientBoostingClassifier,GradientBoostingRegressor,IsolationForest,RandomForestClassifier,RandomForestRegressor,RandomTreesEmbedding,VotingClassifier\n",
      "\n",
      "===> feature_extraction\n",
      "DictVectorizer,FeatureHasher\n",
      "\n",
      "===> feature_selection\n",
      "GenericUnivariateSelect,RFE,RFECV,SelectFdr,SelectFpr,SelectFromModel,SelectFwe,SelectKBest,SelectPercentile,VarianceThreshold\n",
      "\n",
      "===> gaussian_process\n",
      "GaussianProcess,GaussianProcessClassifier,GaussianProcessRegressor\n",
      "\n",
      "===> grid_search\n",
      "GridSearchCV,RandomizedSearchCV\n",
      "\n",
      "===> isotonic\n",
      "IsotonicRegression\n",
      "\n",
      "===> kernel_approximation\n",
      "AdditiveChi2Sampler,Nystroem,RBFSampler,SkewedChi2Sampler\n",
      "\n",
      "===> kernel_ridge\n",
      "KernelRidge\n",
      "\n",
      "===> linear_model\n",
      "ARDRegression,BayesianRidge,ElasticNet,ElasticNetCV,HuberRegressor,Lars,LarsCV,Lasso,LassoCV,LassoLars,LassoLarsCV,LassoLarsIC,LinearRegression,LogisticRegression,LogisticRegressionCV,MultiTaskElasticNet,MultiTaskElasticNetCV,MultiTaskLasso,MultiTaskLassoCV,OrthogonalMatchingPursuit,OrthogonalMatchingPursuitCV,PassiveAggressiveClassifier,PassiveAggressiveRegressor,Perceptron,RANSACRegressor,RandomizedLasso,RandomizedLogisticRegression,Ridge,RidgeCV,RidgeClassifier,RidgeClassifierCV,SGDClassifier,SGDRegressor,TheilSenRegressor\n",
      "\n",
      "===> manifold\n",
      "Isomap,LocallyLinearEmbedding,MDS,SpectralEmbedding,TSNE\n",
      "\n",
      "===> mixture\n",
      "BayesianGaussianMixture,DPGMM,GMM,GaussianMixture,VBGMM\n",
      "\n",
      "===> model_selection\n",
      "GridSearchCV,RandomizedSearchCV\n",
      "\n",
      "===> multiclass\n",
      "LabelBinarizer,OneVsOneClassifier,OneVsRestClassifier,OutputCodeClassifier,_ConstantPredictor\n",
      "\n",
      "===> multioutput\n",
      "ClassifierChain,MultiOutputClassifier,MultiOutputEstimator,MultiOutputRegressor\n",
      "\n",
      "===> naive_bayes\n",
      "BaseDiscreteNB,BernoulliNB,GaussianNB,LabelBinarizer,MultinomialNB\n",
      "\n",
      "===> neighbors\n",
      "KNeighborsClassifier,KNeighborsRegressor,KernelDensity,LSHForest,LocalOutlierFactor,NearestCentroid,NearestNeighbors,RadiusNeighborsClassifier,RadiusNeighborsRegressor\n",
      "\n",
      "===> neural_network\n",
      "BernoulliRBM,MLPClassifier,MLPRegressor\n",
      "\n",
      "===> pipeline\n",
      "FeatureUnion,Pipeline\n",
      "\n",
      "===> preprocessing\n",
      "Binarizer,FunctionTransformer,Imputer,KernelCenterer,LabelBinarizer,LabelEncoder,MaxAbsScaler,MinMaxScaler,MultiLabelBinarizer,Normalizer,OneHotEncoder,PolynomialFeatures,QuantileTransformer,RobustScaler,StandardScaler\n",
      "\n",
      "===> random_projection\n",
      "BaseRandomProjection,GaussianRandomProjection,SparseRandomProjection\n",
      "\n",
      "===> semi_supervised\n",
      "LabelPropagation,LabelSpreading\n",
      "\n",
      "===> svm\n",
      "LinearSVC,LinearSVR,NuSVC,NuSVR,OneClassSVM,SVC,SVR,so\n",
      "\n",
      "===> tree\n",
      "DecisionTreeClassifier,DecisionTreeRegressor,ExtraTreeClassifier,ExtraTreeRegressor\n",
      "\n",
      "===> discriminant_analysis\n",
      "LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis,StandardScaler\n"
     ]
    }
   ],
   "source": [
    "algos = get_sklearn_algorithms(True)\n",
    "for key in algos.keys():\n",
    "    print (\"\\n===>\",key)\n",
    "    algos_ = []\n",
    "    for algo in algos[key]:\n",
    "        classe_algo = str(algo)\n",
    "        nom_algo    = classe_algo[str(classe_algo).rfind(\".\")+1:str(classe_algo).rfind(\"'\")]\n",
    "        algos_.append(nom_algo)\n",
    "    print (\",\".join(algos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability calibration w\n",
      "0.0718562874251497\n",
      "==============================\n",
      "Isotonic regression model\n",
      "X should be a 1d array\n",
      "==============================\n",
      "Binarize labels in a one-\n",
      "fit() takes 2 positional arguments but 3 were give\n",
      "==============================\n",
      "Encode labels with value\n",
      "fit() takes 2 positional arguments but 3 were give\n",
      "==============================\n",
      "Linear Support Vector Cla\n",
      "1.0\n",
      "==============================\n",
      "__init__() missing 1 required positional argument:\n",
      "==============================\n",
      "Sigmoid regression model.\n",
      "bad input shape (831, 26)\n",
      "==============================\n",
      "Perform Affinity Propagat\n",
      "'AffinityPropagation' object has no attribute 'sco\n",
      "==============================\n",
      "Agglomerative Cluste\n",
      "'AgglomerativeClustering' object has no attribute \n",
      "==============================\n",
      "Implements the Birch clus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/cluster/birch.py:77: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  node1_dist, node2_dist = dist[[farthest_idx]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Birch' object has no attribute 'score'\n",
      "==============================\n",
      "Perform DBSCAN clustering\n",
      "'DBSCAN' object has no attribute 'score'\n",
      "==============================\n",
      "Agglomerate features.\n",
      "'FeatureAgglomeration' object has no attribute 'sc\n",
      "==============================\n",
      "K-Means clustering\n",
      "\n",
      "    R\n",
      "-1808730.0741853998\n",
      "==============================\n",
      "Mean shift clustering usi\n",
      "'MeanShift' object has no attribute 'score'\n",
      "==============================\n",
      "Mini-Batch K-Means cluste\n",
      "-1915379.2622767836\n",
      "==============================\n",
      "Spectral biclustering (Kl\n",
      "'SpectralBiclustering' object has no attribute 'sc\n",
      "==============================\n",
      "Apply clustering to a pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SpectralClustering' object has no attribute 'scor\n",
      "==============================\n",
      "Spectral Co-Clustering al\n",
      "'SpectralCoclustering' object has no attribute 'sc\n",
      "==============================\n",
      "An object for detecting o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.826861734885895 > -75.828412505381593)\n",
      "  % (det, previous_det), RuntimeWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.828073190255893 > -75.829884932918858)\n",
      "  % (det, previous_det), RuntimeWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.931656668995089 > -75.951881849009283)\n",
      "  % (det, previous_det), RuntimeWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.881901488009106 > -75.943550743094150)\n",
      "  % (det, previous_det), RuntimeWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.883910583014995 > -75.903660072680751)\n",
      "  % (det, previous_det), RuntimeWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.906461059904217 > -75.908577043017573)\n",
      "  % (det, previous_det), RuntimeWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.879021361477939 > -75.900724864315819)\n",
      "  % (det, previous_det), RuntimeWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880239520958084\n",
      "==============================\n",
      "Maximum likelihood covari\n",
      "-155.42077501527802\n",
      "==============================\n",
      "Sparse inverse covariance\n",
      "Non SPD result: the system is too ill-conditioned \n",
      "==============================\n",
      "Sparse inverse covariance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py:1965: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-55.41630605836486\n",
      "==============================\n",
      "LedoitWolf Estimator\n",
      "-96.98759650902036\n",
      "==============================\n",
      "Minimum Covariance Determ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.797149089768325 > -75.800174628040139)\n",
      "  % (det, previous_det), RuntimeWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.840140562310310 > -75.845282910174660)\n",
      "  % (det, previous_det), RuntimeWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.767425536998104 > -75.858756463812227)\n",
      "  % (det, previous_det), RuntimeWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/covariance/robust_covariance.py:165: RuntimeWarning: Warning! det > previous_det (-75.815991578647299 > -75.863352530570836)\n",
      "  % (det, previous_det), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n",
      "==============================\n",
      "Oracle Approximating Shri\n",
      "-80.14488750371024\n",
      "==============================\n",
      "Covariance estimator with\n",
      "-106.38556122092453\n",
      "==============================\n",
      "CCA Canonical Correlation\n",
      "0.0\n",
      "==============================\n",
      "PLSCanonical implements\n",
      "0.0\n",
      "==============================\n",
      "PLS regression\n",
      "\n",
      "    PLSRe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:287: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "==============================\n",
      "Partial Least Square SVD\n",
      "'PLSSVD' object has no attribute 'score'\n",
      "==============================\n",
      "Dictionary learning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-90b8cb9f6d2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mname\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0malgorithme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/dict_learning.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             return_n_iter=True)\n\u001b[0m\u001b[1;32m   1108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/dict_learning.py\u001b[0m in \u001b[0;36mdict_learning\u001b[0;34m(X, n_components, alpha, max_iter, tol, method, n_jobs, dict_init, code_init, callback, verbose, random_state, return_n_iter)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# Update code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         code = sparse_encode(X, dictionary, algorithm=method, alpha=alpha,\n\u001b[0;32m--> 531\u001b[0;31m                              init=code, n_jobs=n_jobs)\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Update dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         dictionary, residuals = _update_dict(dictionary.T, X.T, code.T,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/dict_learning.py\u001b[0m in \u001b[0;36msparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, check_input, verbose)\u001b[0m\n\u001b[1;32m    288\u001b[0m                               \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                               \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                               verbose=verbose)\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/dict_learning.py\u001b[0m in \u001b[0;36m_sparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, regularization, copy_cov, init, max_iter, check_input, verbose)\u001b[0m\n\u001b[1;32m    115\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                                    precompute=gram, fit_path=False)\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mlasso_lars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0mnew_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasso_lars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, Xy)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         self._fit(X, y, max_iter=max_iter, alpha=alpha, fit_path=self.fit_path,\n\u001b[0;32m--> 709\u001b[0;31m                   Xy=Xy)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_iter, alpha, fit_path, Xy)\u001b[0m\n\u001b[1;32m    666\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                     \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_n_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m                     positive=self.positive)\n\u001b[0m\u001b[1;32m    669\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py\u001b[0m in \u001b[0;36mlars_path\u001b[0;34m(X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[1;32m    288\u001b[0m                                         \u001b[0mtrans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                                         \u001b[0moverwrite_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                                         **solve_triangular_args)\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_active\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_active\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_active\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_active\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36msolve_triangular\u001b[0;34m(a, b, trans, lower, unit_diagonal, overwrite_b, debug, check_finite)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mtrtrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trtrs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     x, info = trtrs(a1, b1, overwrite_b=overwrite_b, lower=lower,\n\u001b[0;32m--> 347\u001b[0;31m                     trans=trans, unitdiag=unit_diagonal)\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "performances               = {}\n",
    "modeles_a_tester           = []\n",
    "classes_de_models_a_tester = algos.keys()\n",
    "best_algorithm = 0\n",
    "best_perf = 0\n",
    "for classe_de_models in classes_de_models_a_tester:\n",
    "    modeles_a_tester.extend(algos[classe_de_models])\n",
    "    \n",
    "for pointeur_vers_algo in modeles_a_tester:\n",
    "    try:\n",
    "        algorithme = pointeur_vers_algo()\n",
    "        doc        = algorithme.__doc__\n",
    "        name       = doc[:min(doc.find(\":\"), 25)].strip()\n",
    "        print (name)\n",
    "        algorithme.fit(X_train, y_train)\n",
    "        performance = algorithme.score(X_test, y_test)\n",
    "        print (performance)\n",
    "        if performance >  best_perf:\n",
    "            best_algorithm = algorithme\n",
    "            best_perf = performance\n",
    "            \n",
    "        if 0<performance and performance<1:\n",
    "            performances[name] = [performance]\n",
    "    except Exception as e:\n",
    "        if \"label\" in str(e): print (\"Algo de classification\")\n",
    "        else                : print (str(e)[:50])\n",
    "    print(\"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
